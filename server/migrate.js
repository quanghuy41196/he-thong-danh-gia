/**
 * Database Migration Tool
 * T·ª± ƒë·ªông ch·∫°y c√°c file migration SQL theo th·ª© t·ª±
 * 
 * Usage: npm run migrate
 */

import pg from 'pg';
import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';
import { config } from 'dotenv';

const currentFilePath = fileURLToPath(import.meta.url);
const currentDir = path.dirname(currentFilePath);

// Load .env t·ª´ th∆∞ m·ª•c server
config({ path: path.join(currentDir, '.env') });

const { Pool } = pg;

const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

// Database connection
const pool = new Pool({
  user: process.env.DB_USER || 'postgres',
  host: process.env.DB_HOST || 'localhost',
  database: process.env.DB_NAME || 'he_thong_danh_gia',
  password: process.env.DB_PASSWORD,
  port: parseInt(process.env.DB_PORT || '5432'),
});

// T·∫°o b·∫£ng tracking migrations
async function createMigrationTable() {
  await pool.query(`
    CREATE TABLE IF NOT EXISTS _migrations (
      id SERIAL PRIMARY KEY,
      name VARCHAR(255) UNIQUE NOT NULL,
      executed_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
    )
  `);
}

// L·∫•y danh s√°ch migrations ƒë√£ ch·∫°y
async function getExecutedMigrations() {
  const result = await pool.query('SELECT name FROM _migrations ORDER BY id');
  return result.rows.map(row => row.name);
}

// ƒê√°nh d·∫•u migration ƒë√£ ch·∫°y
async function markMigrationExecuted(name) {
  await pool.query('INSERT INTO _migrations (name) VALUES ($1)', [name]);
}

// Ch·∫°y migration
async function runMigration(filePath, fileName) {
  console.log(`\nüìÑ Running: ${fileName}`);
  
  const sql = fs.readFileSync(filePath, 'utf-8');
  
  try {
    await pool.query(sql);
    await markMigrationExecuted(fileName);
    console.log(`   ‚úÖ Success`);
    return true;
  } catch (error) {
    console.error(`   ‚ùå Failed: ${error.message}`);
    return false;
  }
}

// Main function
async function migrate() {
  console.log('üîÑ Database Migration Tool');
  console.log('==========================');
  
  try {
    // Test connection
    await pool.query('SELECT NOW()');
    console.log('‚úÖ Connected to PostgreSQL');
    
    // T·∫°o b·∫£ng tracking
    await createMigrationTable();
    
    // L·∫•y migrations ƒë√£ ch·∫°y
    const executedMigrations = await getExecutedMigrations();
    console.log(`üìã Executed migrations: ${executedMigrations.length}`);
    
    // T√¨m file migrations
    const migrationsDir = path.join(currentDir, 'migrations');
    
    if (!fs.existsSync(migrationsDir)) {
      console.log('üìÅ Creating migrations directory...');
      fs.mkdirSync(migrationsDir, { recursive: true });
    }
    
    const files = fs.readdirSync(migrationsDir)
      .filter(f => f.endsWith('.sql'))
      .sort();
    
    if (files.length === 0) {
      console.log('\n‚ö†Ô∏è  No migration files found in /migrations');
      return;
    }
    
    // Ch·∫°y migrations ch∆∞a executed
    let newMigrations = 0;
    let failedMigrations = 0;
    
    for (const file of files) {
      if (!executedMigrations.includes(file)) {
        const success = await runMigration(
          path.join(migrationsDir, file),
          file
        );
        if (success) {
          newMigrations++;
        } else {
          failedMigrations++;
          break; // D·ª´ng l·∫°i n·∫øu c√≥ l·ªói
        }
      }
    }
    
    console.log('\n==========================');
    if (newMigrations > 0) {
      console.log(`‚úÖ Applied ${newMigrations} new migration(s)`);
    } else if (failedMigrations === 0) {
      console.log('‚úÖ Database is up to date');
    }
    
    if (failedMigrations > 0) {
      console.log(`‚ùå ${failedMigrations} migration(s) failed`);
      process.exit(1);
    }
    
  } catch (error) {
    console.error('‚ùå Migration failed:', error.message);
    process.exit(1);
  } finally {
    await pool.end();
  }
}

// Run
migrate();
